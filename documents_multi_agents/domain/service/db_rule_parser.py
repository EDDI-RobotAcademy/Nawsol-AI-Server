"""
DB ê¸°ë°˜ ê·œì¹™ íŒŒì„œ
IE_RULE í…Œì´ë¸”ì—ì„œ í‚¤ì›Œë“œë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ë¶„ë¥˜
"""

import re
from typing import Optional, Tuple, List
from dataclasses import dataclass

from ieinfo.infrastructure.repository.ie_rule_repository_impl import IERuleRepositoryImpl
from ieinfo.infrastructure.orm.ie_info import IEType
from config.database.session import get_db_session
from util.log.log import Log

logger = Log.get_logger()


@dataclass
class ParsedTransaction:
    """íŒŒì‹±ëœ ê±°ë˜ ì •ë³´"""
    field_name: str  # í•­ëª©ëª…
    amount: str  # ê¸ˆì•¡
    transaction_type: str  # 'income' or 'expense'
    confidence: float  # ì‹ ë¢°ë„ (0.0 ~ 1.0)
    matched_keyword: str  # ë§¤ì¹­ëœ í‚¤ì›Œë“œ


class DBRuleBasedParser:
    """DB ê¸°ë°˜ ì†Œë“/ì§€ì¶œ ë¶„ë¥˜ íŒŒì„œ"""
    
    def __init__(self):
        self.db_session = get_db_session()
        self.rule_repo = IERuleRepositoryImpl(self.db_session)
        
        # DBì—ì„œ í‚¤ì›Œë“œ ë¡œë“œ
        self._load_keywords_from_db()
        
        # ê¸ˆì•¡ íŒ¨í„´
        self.amount_patterns = [
            r'(\d{1,3}(?:,\d{3})+)\s*ì›',  # 1,000,000ì›
            r'(\d+)\s*ì›',                  # 1000000ì›
            r'â‚©\s*(\d{1,3}(?:,\d{3})+)',   # â‚©1,000,000
            r'KRW\s*(\d{1,3}(?:,\d{3})+)', # KRW 1,000,000
        ]
    
    def _load_keywords_from_db(self):
        """DBì—ì„œ í‚¤ì›Œë“œ ë¡œë“œ"""
        try:
            self.income_keywords = self.rule_repo.find_all_keywords_by_type(IEType.INCOME)
            self.expense_keywords = self.rule_repo.find_all_keywords_by_type(IEType.EXPENSE)
            
            logger.info(f"ğŸ“š [DB] ê·œì¹™ ë¡œë“œ ì™„ë£Œ: ì†Œë“ {len(self.income_keywords)}ê°œ, ì§€ì¶œ {len(self.expense_keywords)}ê°œ")
            
        except Exception as e:
            logger.error(f"[DB] ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.income_keywords = []
            self.expense_keywords = []
    
    def reload_keywords(self):
        """í‚¤ì›Œë“œ ì¬ë¡œë“œ (GPTê°€ ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€ í›„ í˜¸ì¶œ)"""
        logger.info("ğŸ”„ [DB] ê·œì¹™ ì¬ë¡œë“œ ì¤‘...")
        self._load_keywords_from_db()
    
    def parse_line(self, line: str, doc_type: str = None) -> Optional[ParsedTransaction]:
        """
        í•œ ì¤„ì˜ í…ìŠ¤íŠ¸ì—ì„œ ê±°ë˜ ì •ë³´ íŒŒì‹±
        
        Args:
            line: "ê¸‰ì—¬: 3000000" ê°™ì€ í˜•ì‹ì˜ í…ìŠ¤íŠ¸
            doc_type: ë¬¸ì„œ íƒ€ì… íŒíŠ¸ ('ì†Œë“', 'ì§€ì¶œ', None)
        
        Returns:
            ParsedTransaction ë˜ëŠ” None
        """
        # 1. ê¸ˆì•¡ ì¶”ì¶œ
        amount = self._extract_amount(line)
        if not amount:
            return None
        
        # 2. í•­ëª©ëª… ì¶”ì¶œ (ì½œë¡  ì•ë¶€ë¶„)
        field_name = self._extract_field_name(line)
        if not field_name:
            return None
        
        # 3. DB ê¸°ë°˜ ë¶„ë¥˜
        trans_type, confidence, matched_keyword = self._classify_with_db(
            field_name, 
            doc_type
        )
        
        if not trans_type:
            return None
        
        return ParsedTransaction(
            field_name=field_name,
            amount=amount,
            transaction_type=trans_type,
            confidence=confidence,
            matched_keyword=matched_keyword
        )
    
    def _extract_amount(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê¸ˆì•¡ ì¶”ì¶œ"""
        for pattern in self.amount_patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    amount_str = match.group(1).replace(',', '').strip()
                    amount_int = int(amount_str)
                    
                    # ë¹„ì •ìƒì ì¸ ê¸ˆì•¡ í•„í„°ë§
                    if 1 <= amount_int <= 1000000000:
                        return amount_str
                except (ValueError, IndexError):
                    continue
        return None
    
    def _extract_field_name(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•­ëª©ëª… ì¶”ì¶œ"""
        match = re.match(r'^([^:]+):', text)
        if match:
            field_name = match.group(1).strip()
            field_name = field_name.replace('_', ' ')
            return field_name
        return None
    
    def _classify_with_db(
        self, 
        field_name: str, 
        doc_type_hint: Optional[str] = None
    ) -> Tuple[Optional[str], float, str]:
        """
        DB í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        
        Returns:
            (transaction_type, confidence, matched_keyword)
        """
        field_lower = field_name.lower()
        
        # === ì†Œë“ í‚¤ì›Œë“œ ë§¤ì¹­ ===
        for keyword in self.income_keywords:
            if keyword.lower() in field_lower:
                confidence = 1.0  # DBì— ìˆëŠ” í‚¤ì›Œë“œëŠ” 100% ì‹ ë¢°
                logger.debug(f"âœ… [DB-RULE] ì†Œë“ ë§¤ì¹­: '{keyword}' in '{field_name}' (ì‹ ë¢°ë„: 1.0)")
                return 'income', confidence, keyword
        
        # === ì§€ì¶œ í‚¤ì›Œë“œ ë§¤ì¹­ ===
        for keyword in self.expense_keywords:
            if keyword.lower() in field_lower:
                confidence = 1.0
                logger.debug(f"âœ… [DB-RULE] ì§€ì¶œ ë§¤ì¹­: '{keyword}' in '{field_name}' (ì‹ ë¢°ë„: 1.0)")
                return 'expense', confidence, keyword
        
        # === ë§¤ì¹­ ì‹¤íŒ¨ ===
        logger.debug(f"âŒ [DB-RULE] í‚¤ì›Œë“œ ì—†ìŒ: '{field_name}' â†’ GPT í•„ìš”")
        return None, 0.0, ""
    
    def get_statistics(self) -> dict:
        """í˜„ì¬ ê·œì¹™ í†µê³„"""
        return {
            'income_keywords': len(self.income_keywords),
            'expense_keywords': len(self.expense_keywords),
            'total_keywords': len(self.income_keywords) + len(self.expense_keywords)
        }
    
    def __del__(self):
        """ì†Œë©¸ì: DB ì„¸ì…˜ ì¢…ë£Œ"""
        if hasattr(self, 'db_session'):
            self.db_session.close()
