"""
í•˜ì´ë¸Œë¦¬ë“œ íŒŒì„œ: DB ê·œì¹™ ê¸°ë°˜ ìš°ì„ , ì‹¤íŒ¨ ì‹œ GPT + ìë™ í•™ìŠµ
"""

import json
from typing import Dict, Any, Tuple
from documents_multi_agents.domain.service.db_rule_parser import DBRuleBasedParser, ParsedTransaction
from ieinfo.infrastructure.repository.ie_rule_repository_impl import IERuleRepositoryImpl
from ieinfo.infrastructure.orm.ie_info import IEType
from config.database.session import get_db_session
from util.log.log import Log

logger = Log.get_logger()


class HybridParser:
    """
    DB ê·œì¹™ ê¸°ë°˜ íŒŒì„œ + GPT í´ë°± + ìë™ í•™ìŠµ
    
    ì²˜ë¦¬ íë¦„:
    1. DBì— í‚¤ì›Œë“œ ìˆìŒ â†’ ê·œì¹™ ê¸°ë°˜ ì„±ê³µ
    2. DBì— í‚¤ì›Œë“œ ì—†ìŒ â†’ GPT ë¶„ë¥˜ + DBì— ìƒˆ í‚¤ì›Œë“œ ì €ì¥
    """
    
    def __init__(self):
        self.db_parser = DBRuleBasedParser()
        self.db_session = get_db_session()
        self.rule_repo = IERuleRepositoryImpl(self.db_session)
        
        # í†µê³„ ìˆ˜ì§‘ìš©
        self.stats = {
            'total_items': 0,
            'db_rule_success': 0,
            'gpt_fallback': 0,
            'new_keywords_learned': 0
        }
    
    def classify_item(
        self, 
        field_name: str, 
        value: str,
        doc_type_hint: str = None
    ) -> Tuple[str, str, Dict[str, Any]]:
        """
        ë‹¨ì¼ í•­ëª© ë¶„ë¥˜
        
        Args:
            field_name: í•­ëª©ëª… (ì˜ˆ: "ê¸‰ì—¬")
            value: ê¸ˆì•¡ (ì˜ˆ: "3000000")
            doc_type_hint: ë¬¸ì„œ íƒ€ì… íŒíŠ¸ ('ì†Œë“', 'ì§€ì¶œ', None)
        
        Returns:
            (classified_type, category, metadata)
        """
        self.stats['total_items'] += 1
        
        # DB ê·œì¹™ ê¸°ë°˜ íŒŒì‹± ì‹œë„
        line_text = f"{field_name}: {value}"
        parsed = self.db_parser.parse_line(line_text, doc_type_hint)
        
        if parsed:
            # âœ… DB ê·œì¹™ ì„±ê³µ
            self.stats['db_rule_success'] += 1
            
            logger.info(f"âœ… [DB-RULE] '{field_name}' â†’ {parsed.transaction_type} "
                       f"(í‚¤ì›Œë“œ: '{parsed.matched_keyword}')")
            
            return parsed.transaction_type, self._get_category(parsed), {
                'method': 'db_rule',
                'confidence': parsed.confidence,
                'matched_keyword': parsed.matched_keyword,
                'original_field': field_name,
                'amount': value
            }
        else:
            # âš ï¸ DBì— í‚¤ì›Œë“œ ì—†ìŒ â†’ GPT í•„ìš”
            self.stats['gpt_fallback'] += 1
            
            logger.warning(f"âš ï¸  [NEED-GPT] '{field_name}' (DBì— í‚¤ì›Œë“œ ì—†ìŒ)")
            
            return None, None, {
                'method': 'needs_gpt',
                'confidence': 0.0,
                'reason': 'DBì— í‚¤ì›Œë“œ ì—†ìŒ',
                'original_field': field_name,
                'amount': value
            }
    
    def learn_from_gpt_result(self, field_name: str, gpt_classified_type: str) -> bool:
        """
        GPT ë¶„ë¥˜ ê²°ê³¼ë¥¼ DBì— í•™ìŠµ
        
        Args:
            field_name: í•­ëª©ëª… (ì˜ˆ: "ê¸°íƒ€ìˆ˜ë‹¹")
            gpt_classified_type: GPTê°€ ë¶„ë¥˜í•œ íƒ€ì… ('income' or 'expense')
        
        Returns:
            í•™ìŠµ ì„±ê³µ ì—¬ë¶€
        """
        # í‚¤ì›Œë“œ ì¶”ì¶œ (í•­ëª©ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì°¾ê¸°)
        keyword = self._extract_core_keyword(field_name)
        
        # ì´ë¯¸ DBì— ìˆëŠ”ì§€ í™•ì¸
        if self.rule_repo.keyword_exists(keyword):
            logger.debug(f"[LEARN] í‚¤ì›Œë“œ ì´ë¯¸ ì¡´ì¬: {keyword}")
            return False
        
        # IEType ë³€í™˜
        ie_type = IEType.INCOME if gpt_classified_type == 'income' else IEType.EXPENSE
        
        # DBì— ì €ì¥
        success = self.rule_repo.save_keyword(keyword, ie_type)
        
        if success:
            self.stats['new_keywords_learned'] += 1
            logger.info(f"ğŸ“ [LEARN] ìƒˆ í‚¤ì›Œë“œ í•™ìŠµ: '{keyword}' â†’ {ie_type.value}")
            
            # íŒŒì„œ í‚¤ì›Œë“œ ì¬ë¡œë“œ
            self.db_parser.reload_keywords()
        
        return success
    
    def _extract_core_keyword(self, field_name: str) -> str:
        """
        í•­ëª©ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        
        ì˜ˆ: "ê¸°íƒ€ìˆ˜ë‹¹" â†’ "ìˆ˜ë‹¹"
            "êµ­ë¯¼ì—°ê¸ˆë³´í—˜ë£Œ" â†’ "ë³´í—˜ë£Œ"
        """
        # ì¼ë‹¨ ì „ì²´ í•­ëª©ëª…ì„ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
        # í–¥í›„ ê°œì„ : NLPë¡œ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ
        return field_name.strip().lower()
    
    def _get_category(self, parsed: ParsedTransaction) -> str:
        """íŒŒì‹± ê²°ê³¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ """
        # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ (ì¶”í›„ í™•ì¥ ê°€ëŠ¥)
        if parsed.transaction_type == 'income':
            return 'ì†Œë“'
        else:
            return 'ì§€ì¶œ'
    
    def get_statistics(self) -> Dict[str, Any]:
        """íŒŒì‹± í†µê³„ ë°˜í™˜"""
        if self.stats['total_items'] == 0:
            return {
                'total_items': 0,
                'db_rule_rate': 0.0,
                'gpt_fallback_rate': 0.0,
                'new_keywords_learned': 0,
                'cost_saving_rate': 0.0
            }
        
        return {
            'total_items': self.stats['total_items'],
            'db_rule_success': self.stats['db_rule_success'],
            'gpt_fallback': self.stats['gpt_fallback'],
            'new_keywords_learned': self.stats['new_keywords_learned'],
            'db_rule_rate': self.stats['db_rule_success'] / self.stats['total_items'],
            'gpt_fallback_rate': self.stats['gpt_fallback'] / self.stats['total_items'],
            'cost_saving_rate': self.stats['db_rule_success'] / self.stats['total_items']
        }
    
    def reset_statistics(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = {
            'total_items': 0,
            'db_rule_success': 0,
            'gpt_fallback': 0,
            'new_keywords_learned': 0
        }
    
    def __del__(self):
        """ì†Œë©¸ì: DB ì„¸ì…˜ ì¢…ë£Œ"""
        if hasattr(self, 'db_session'):
            self.db_session.close()
